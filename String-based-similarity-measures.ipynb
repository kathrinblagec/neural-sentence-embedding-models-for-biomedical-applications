{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# String-based similarity measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "import tarfile\n",
    "import glob, os, sys\n",
    "import pathlib\n",
    "from fnmatch import fnmatch\n",
    "from pycorenlp import StanfordCoreNLP\n",
    "from shutil import rmtree\n",
    "import timeit\n",
    "import numpy as np\n",
    "import utils\n",
    "import operator\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import ngram\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_similarities(annotation_scores, similarities, stop_word_set, name = None,):\n",
    "    \"\"\"Calculate Pearson and Spearman correlation; return values in dictionary\"\"\"  \n",
    "    ppmc = utils.calculate_ppmc(similarities, annotation_scores)\n",
    "    spearman_correlation = utils.calculate_spearman(similarities, annotation_scores)\n",
    "    if name:\n",
    "        results[name, stop_word_set] = {'r' : round(ppmc[0], 3), 'rs' : round(spearman_correlation[0], 3)}\n",
    "    return results\n",
    "\n",
    "def remove_stopwords(sent, stop_word_set):\n",
    "    \"\"\"Remove stopwords and punctuation\"\"\"\n",
    "    # Note: BIOSSES original paper used stop words from https://www.ranks.nl/stopwords\n",
    "    # and following punctuation: (.,!;/-?: colon, mark,)\n",
    "    if stop_word_set == 'ranks':\n",
    "        stop_words = set(ranks_stopwords)\n",
    "    elif stop_word_set == 'stanford_core':\n",
    "        stop_words = set(stanford_core_stopwords) \n",
    "    elif stop_word_set == 'nltk':\n",
    "        stop_words = set(stopwords.words('english')) \n",
    "    punctuation_tokens = set('.,-!;/?:')\n",
    "    word_tokens = word_tokenize(sent)\n",
    "    filtered_sentence = [w for w in word_tokens if not (w in stop_words or w in punctuation_tokens)]\n",
    "    filtered_sentence = ' '.join(filtered_sentence)\n",
    "    #filtered_sentence = stemmer.stem(filtered_sentence)\n",
    "    return filtered_sentence\n",
    "\n",
    "def calculate_string_similarity(strings, method, stop_word_set, N=3):\n",
    "    \"\"\"Calculate string similarities for a list of strings (interleaved sentence pairs)\"\"\"\n",
    "    similarities = []\n",
    "    i= 0\n",
    "    while (i <= len(strings)-1):\n",
    "        if method == 'jaccard':\n",
    "            similarities.append(utils.dist_jaccard(remove_stopwords(strings[i], stop_word_set), remove_stopwords(strings[i+1], stop_word_set)))  \n",
    "        elif method == 'qgram':\n",
    "            similarities.append(utils.dist_qgram(remove_stopwords(strings[i], stop_word_set), remove_stopwords(strings[i+1], stop_word_set), N=N))  \n",
    "        i += 2\n",
    "    similarities = np.array(similarities, dtype=float)\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/matthias/Documents/Intelligence/SDL1 - Embeddings/data/'\n",
    "RANKS_STOPWORDS = 'ranks_stopwords.txt'\n",
    "STANFORD_STOPWORDS = 'stanford_core_stopwords.txt'\n",
    "\n",
    "# Scores assigned by the human experts for each of the 100 sentence pairs\n",
    "ANNOTATION_SCORES = 'annotation_scores_from_github.txt'\n",
    "\n",
    "# Original BIOSSES sentence pairs (no pre-processing)\n",
    "BIOSSES_SENTENCE_PAIRS = 'biosses_sentence_pairs_test_derived_from_github.txt'\n",
    "\n",
    "# Pre-processed sentences (lower-case, words and punctuation separated by whitespaces), one sentence per line.\n",
    "BIOSSES_SENTENCE_PAIRS_PREPROCESSED = 'biosses_sentence_pairs_test_derived_from_github_preprocessed.txt' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Compare stop word lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_word_lists = ['ranks', 'nltk' , 'stanford_core']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stopwords in NLTK list:  153\n",
      "Number of stopwords in RANKS list:  174\n",
      "Number of stopwords in Stanford Core list:  257\n"
     ]
    }
   ],
   "source": [
    "nltk_stopwords = stopwords.words('english')\n",
    "ranks_stopwords = []\n",
    "stanford_core_stopwords = []\n",
    "\n",
    "with open(os.path.join(DATA_DIR, RANKS_STOPWORDS), 'r') as words:\n",
    "    for i in words:\n",
    "        ranks_stopwords.append(i.strip())\n",
    "\n",
    "with open(os.path.join(DATA_DIR, STANFORD_STOPWORDS), 'r') as words:\n",
    "    for i in words:\n",
    "        stanford_core_stopwords.append(i.strip())\n",
    "\n",
    "print(\"Number of stopwords in NLTK list: \", len(nltk_stopwords))\n",
    "print(\"Number of stopwords in RANKS list: \", len(ranks_stopwords))\n",
    "print(\"Number of stopwords in Stanford Core list: \", len(stanford_core_stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set(nltk_stopwords).symmetric_difference(set(ranks_stopwords))\n",
    "#set(nltk_stopwords)-(set(ranks_stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set(ranks_stopwords)-(set(nltk_stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(nltk_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotation scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read scores assigned by human experts for the 100 sentence pairs into np.array\n",
    "with open(os.path.join(DATA_DIR, ANNOTATION_SCORES), \"r\", encoding=\"utf-8\") as scores:\n",
    "    annotation_scores = np.loadtxt(scores)\n",
    "\n",
    "#print(annotation_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Jaccard and Q-gram measures for BIOSSES sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process sentences with StanfordCoreNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = StanfordCoreNLP('http://localhost:9000')\n",
    "\n",
    "first_sentence = True\n",
    "\n",
    "with open(os.path.join(DATA_DIR, BIOSSES_SENTENCE_PAIRS), 'r') as fin, \\\n",
    "     open(os.path.join(DATA_DIR, BIOSSES_SENTENCE_PAIRS_PREPROCESSED), 'w') as fout:\n",
    "    for line in fin:\n",
    "        res = nlp.annotate(line,properties={'annotators': 'tokenize','outputFormat': 'json','timeout': 10000,})\n",
    "        for t in res[\"tokens\"]:\n",
    "            if '-LRB-' in t[\"word\"]:\n",
    "                t[\"word\"] = \"(\"\n",
    "            if '-RRB-' in t[\"word\"]:\n",
    "                t[\"word\"] = \")\"\n",
    "            if '-LCB-' in t[\"word\"]:\n",
    "                t[\"word\"] = \"{\"\n",
    "            if '-RCB-' in t[\"word\"]:\n",
    "                t[\"word\"] = \"}\"\n",
    "            if '-LSB-' in t[\"word\"]:\n",
    "                t[\"word\"] = \"[\"\n",
    "            if '-RSB-' in t[\"word\"]:\n",
    "                t[\"word\"] = \"]\"\t\n",
    "            if '-' in t[\"word\"]:\n",
    "                t[\"word\"] = t[\"word\"].replace('-', ' - ')\n",
    "        sentence = (\" \".join([t[\"word\"] for t in res[\"tokens\"]]))\n",
    "        sentence = sentence.lower().strip()\n",
    "        if first_sentence == False:\n",
    "            sentence = \"\\n\" + sentence \n",
    "        else:\n",
    "            first_sentence = False\n",
    "        fout.write(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read pre-processed sentence pairs into list\n",
    "strings = []\n",
    "with open(os.path.join(DATA_DIR, BIOSSES_SENTENCE_PAIRS_PREPROCESSED), 'r') as BIOSSES_sentences_tokenized:\n",
    "    for line in BIOSSES_sentences_tokenized:\n",
    "        strings.append(line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccard distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in stop_word_lists:\n",
    "    evaluate_similarities(annotation_scores, calculate_string_similarity(strings, \n",
    "    method='jaccard', stop_word_set=i), i, 'Jaccard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-gram distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in stop_word_lists:\n",
    "    evaluate_similarities(annotation_scores, calculate_string_similarity(strings, \n",
    "    method='qgram', stop_word_set=i), i, 'Qgram' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>r</th>\n",
       "      <th>rs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Jaccard</th>\n",
       "      <th>ranks</th>\n",
       "      <td>0.746</td>\n",
       "      <td>0.758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk</th>\n",
       "      <td>0.751</td>\n",
       "      <td>0.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stanford_core</th>\n",
       "      <td>0.767</td>\n",
       "      <td>0.789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Qgram</th>\n",
       "      <th>ranks</th>\n",
       "      <td>0.720</td>\n",
       "      <td>0.763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk</th>\n",
       "      <td>0.723</td>\n",
       "      <td>0.763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stanford_core</th>\n",
       "      <td>0.727</td>\n",
       "      <td>0.769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           r     rs\n",
       "Jaccard ranks          0.746  0.758\n",
       "        nltk           0.751  0.764\n",
       "        stanford_core  0.767  0.789\n",
       "Qgram   ranks          0.720  0.763\n",
       "        nltk           0.723  0.763\n",
       "        stanford_core  0.727  0.769"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_based_measures_results_df = pd.DataFrame.from_dict(results).transpose()\n",
    "string_based_measures_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "string_based_measures_results_df.to_csv(os.path.join(DATA_DIR, 'string_based_measures_results.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
